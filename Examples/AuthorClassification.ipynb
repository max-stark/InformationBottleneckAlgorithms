{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Identification Using The Information Bottleneck Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "author_list = []\n",
    "number_of_authors = 0\n",
    "file_idx = 0\n",
    "\n",
    "for file in os.listdir('books/'):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(os.path.join('books/'+file), 'r',encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                for word in line.split():\n",
    "                    word1 = \" \".join(re.findall('[a-zA-ZäöüßÄÖÜẞ]+', word))\n",
    "                    if not word1 in word_list:\n",
    "                        word_list.append(word1.lower())\n",
    "        number_of_authors += 1\n",
    "        author_list.append(file.split('_')[0])\n",
    "        \n",
    "\n",
    "p_x_y = np.zeros((word_list.__len__(),number_of_authors))\n",
    "for file in os.listdir('books/'):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(os.path.join('books/'+file), 'r',encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                for word in line.split():\n",
    "                    word1 = \" \".join(re.findall('[a-zA-ZäöüßÄÖÜẞ]+', word))\n",
    "                    index = word_list.index(word1.lower())\n",
    "                    p_x_y[index,file_idx] += 1\n",
    "        file_idx += 1\n",
    "        \n",
    "p_x_y /= p_x_y.sum()\n",
    "p_y = p_x_y.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p_x_y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_unique_indices = np.nonzero(np.sum(p_x_y!=0,axis=1)>1)[0]\n",
    "p_y = p_y[non_unique_indices]\n",
    "p_x_y = p_x_y[non_unique_indices,:]\n",
    "#non_unique_indices\n",
    "word_list = [word_list[j] for j in non_unique_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table = pd.DataFrame({ 'Pr(Word)' : p_y,\n",
    "                          'Word' : word_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pr(Word)</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.032978</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024685</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.020155</td>\n",
       "      <td>der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015420</td>\n",
       "      <td>ich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.013477</td>\n",
       "      <td>sie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.013346</td>\n",
       "      <td>zu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.012515</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.012216</td>\n",
       "      <td>nicht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.012085</td>\n",
       "      <td>er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.012011</td>\n",
       "      <td>das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.011058</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010582</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.010218</td>\n",
       "      <td>ein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010115</td>\n",
       "      <td>sich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.009900</td>\n",
       "      <td>den</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.009657</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.007630</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.007276</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.007182</td>\n",
       "      <td>ist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.007098</td>\n",
       "      <td>auf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.006668</td>\n",
       "      <td>dem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.006248</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.006192</td>\n",
       "      <td>von</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.006005</td>\n",
       "      <td>aber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.005940</td>\n",
       "      <td>wie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.005884</td>\n",
       "      <td>daß</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.004950</td>\n",
       "      <td>als</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.004922</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.004707</td>\n",
       "      <td>mir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.004567</td>\n",
       "      <td>mich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.004539</td>\n",
       "      <td>nur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.004380</td>\n",
       "      <td>im</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004296</td>\n",
       "      <td>ihr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.004259</td>\n",
       "      <td>auch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.004147</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.003913</td>\n",
       "      <td>eine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.003736</td>\n",
       "      <td>hatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.003670</td>\n",
       "      <td>wenn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003502</td>\n",
       "      <td>noch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.003446</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.003372</td>\n",
       "      <td>des</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.003241</td>\n",
       "      <td>für</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003194</td>\n",
       "      <td>aus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.003017</td>\n",
       "      <td>doch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002933</td>\n",
       "      <td>um</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.002774</td>\n",
       "      <td>dir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.002755</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.002680</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.002671</td>\n",
       "      <td>einen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.002615</td>\n",
       "      <td>schon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pr(Word)   Word\n",
       "27   0.032978    und\n",
       "4    0.024685    die\n",
       "33   0.020155    der\n",
       "12   0.015420    ich\n",
       "68   0.013477    sie\n",
       "20   0.013346     zu\n",
       "90   0.012515     in\n",
       "70   0.012216  nicht\n",
       "236  0.012085     er\n",
       "74   0.012011    das\n",
       "36   0.011058    mit\n",
       "0    0.010582       \n",
       "92   0.010218    ein\n",
       "6    0.010115   sich\n",
       "99   0.009900    den\n",
       "54   0.009657     es\n",
       "416  0.007630    war\n",
       "433  0.007276     du\n",
       "73   0.007182    ist\n",
       "41   0.007098    auf\n",
       "8    0.006668    dem\n",
       "23   0.006248     so\n",
       "116  0.006192    von\n",
       "254  0.006005   aber\n",
       "25   0.005940    wie\n",
       "153  0.005884    daß\n",
       "281  0.004950    als\n",
       "88   0.004922     an\n",
       "67   0.004707    mir\n",
       "30   0.004567   mich\n",
       "178  0.004539    nur\n",
       "104  0.004380     im\n",
       "1    0.004296    ihr\n",
       "157  0.004259   auch\n",
       "86   0.004147    was\n",
       "323  0.003913   eine\n",
       "424  0.003736  hatte\n",
       "89   0.003670   wenn\n",
       "17   0.003502   noch\n",
       "136  0.003446    man\n",
       "57   0.003372    des\n",
       "213  0.003241    für\n",
       "26   0.003194    aus\n",
       "139  0.003017   doch\n",
       "29   0.002933     um\n",
       "338  0.002774    dir\n",
       "131  0.002755     da\n",
       "66   0.002680    vor\n",
       "238  0.002671  einen\n",
       "128  0.002615  schon"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table.sort_values(by='Pr(Word)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###  OPENCL Device #####\n",
      "[<pyopencl.Device 'Intel(R) UHD Graphics 620' on 'Intel(R) OpenCL' at 0x2b404399dc0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [Elapsed Time: 0:00:09] |##################################| (Time:  0:00:09) \n"
     ]
    }
   ],
   "source": [
    "from information_bottleneck.information_bottleneck_algorithms.KLmeansIB_class import KLmeansIB as KLmeans\n",
    "\n",
    "card_T = 10\n",
    "IB_inst = KLmeans(p_x_y+1e-34,\n",
    "                   card_T,\n",
    "                   nror=100)\n",
    "IB_inst.run_IB_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Mutual Information Comp --- \n",
      "-----  KL means IB  ------ \n",
      "MI_XT_s=  0.18965189361022478\n",
      "MI_XY_s=  0.4280667070931024\n",
      "ratio=  0.4430428493215578\n"
     ]
    }
   ],
   "source": [
    "IB_inst.display_MIs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t_given_y, p_x_given_t, p_t = IB_inst.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster index t</th>\n",
       "      <th>words in cluster</th>\n",
       "      <th>p(X=goethe|t)</th>\n",
       "      <th>p(X=kafka|t)</th>\n",
       "      <th>p(X=mann|t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[flehen, spruch, sünde, sacht, suche, edle, li...</td>\n",
       "      <td>0.800816</td>\n",
       "      <td>0.046803</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[innen, unanständige, schwanken, genähert, wär...</td>\n",
       "      <td>0.457520</td>\n",
       "      <td>0.456776</td>\n",
       "      <td>0.085704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[lasse, rohen, deutschen, möchten, letztenmal,...</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.242237</td>\n",
       "      <td>0.280642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[gewendet, fernen, jünger, studien, feine, ver...</td>\n",
       "      <td>0.292243</td>\n",
       "      <td>0.420554</td>\n",
       "      <td>0.287203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[schwindel, wangen, scheiben, erfüllt, bestand...</td>\n",
       "      <td>0.263556</td>\n",
       "      <td>0.324761</td>\n",
       "      <td>0.411683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[ärgerlich, gebrauchen, knochen, ermahnungen, ...</td>\n",
       "      <td>0.026561</td>\n",
       "      <td>0.767008</td>\n",
       "      <td>0.206431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[dunkel, personal, gelernt, bemerkt, entscheid...</td>\n",
       "      <td>0.091347</td>\n",
       "      <td>0.534890</td>\n",
       "      <td>0.373763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[walten, schmecken, loben, zofe, hofe, geschwi...</td>\n",
       "      <td>0.334855</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.642922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[gerichtet, setzt, studiert, heller, sonntags,...</td>\n",
       "      <td>0.172524</td>\n",
       "      <td>0.292090</td>\n",
       "      <td>0.535386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[lebhafter, empfand, erwies, tüchtigen, nachde...</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.294367</td>\n",
       "      <td>0.701775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster index t                                   words in cluster  \\\n",
       "0                0  [flehen, spruch, sünde, sacht, suche, edle, li...   \n",
       "1                1  [innen, unanständige, schwanken, genähert, wär...   \n",
       "2                2  [lasse, rohen, deutschen, möchten, letztenmal,...   \n",
       "3                3  [gewendet, fernen, jünger, studien, feine, ver...   \n",
       "4                4  [schwindel, wangen, scheiben, erfüllt, bestand...   \n",
       "5                5  [ärgerlich, gebrauchen, knochen, ermahnungen, ...   \n",
       "6                6  [dunkel, personal, gelernt, bemerkt, entscheid...   \n",
       "7                7  [walten, schmecken, loben, zofe, hofe, geschwi...   \n",
       "8                8  [gerichtet, setzt, studiert, heller, sonntags,...   \n",
       "9                9  [lebhafter, empfand, erwies, tüchtigen, nachde...   \n",
       "\n",
       "   p(X=goethe|t)  p(X=kafka|t)  p(X=mann|t)  \n",
       "0       0.800816      0.046803     0.152381  \n",
       "1       0.457520      0.456776     0.085704  \n",
       "2       0.477121      0.242237     0.280642  \n",
       "3       0.292243      0.420554     0.287203  \n",
       "4       0.263556      0.324761     0.411683  \n",
       "5       0.026561      0.767008     0.206431  \n",
       "6       0.091347      0.534890     0.373763  \n",
       "7       0.334855      0.022222     0.642922  \n",
       "8       0.172524      0.292090     0.535386  \n",
       "9       0.003858      0.294367     0.701775  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_ind = p_t_given_y.argmax(axis=1)\n",
    "word_list = np.asarray(word_list)\n",
    "\n",
    "words_in_cluster = [None]*card_T\n",
    "\n",
    "for t in range(card_T):\n",
    "    indices = np.argsort(p_y[np.argwhere(cluster_ind == t)][:, 0])\n",
    "    words_in_cluster[t] = []\n",
    "    for item in word_list[np.argwhere(cluster_ind == t)[indices]]:\n",
    "        words_in_cluster[t].append(item[0])\n",
    "    \n",
    "result_dataframe = pd.DataFrame(\n",
    "    {'cluster index t' : np.arange(card_T),\n",
    "     'words in cluster': words_in_cluster\n",
    "    }\n",
    ")\n",
    "for x in range(p_x_given_t.shape[1]):\n",
    "    result_dataframe['p(X='+author_list[x]+'|t)'] = pd.Series(p_x_given_t[:,x])\n",
    "result_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
